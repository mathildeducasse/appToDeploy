# Imports:
import io
from PIL import Image
import streamlit as st
import pandas as pd


# Title
st.title("Project Report ")
st.subheader("Downscaling physics-based water simulation with Convulutional-LSTM and Super-Resolution")

# Text desciption presentation
st.write("""We present the application of deep learning techniques for downscaling physics-based water simulation with space-time architectures. We create a mapping between a sequence of low resolution (LR) water height and speed simulation and its corre- sponding high resolution (HR) simulation sequence. We utilized Convolutional-LSTM followed by Super-Resolution blocks. We experiment with multiple losses
by combining RMSE, Structural Similarity, and our contribution : region-specific
Structural Similarity.
We adapt the techniques to take into account the little amount of data we have. We
compare the use of our architecture on input data that was statistically up-scaled
with Bayesian interpolation with input data that is still in a low resolution quality.
We show that ConvLSTM+SR works surprisingly well on data that was interpolated,
and is able to lean interesting pattern even with few data. We speculate that this
architecture will scale well to more complex and realistic data. \n""")




#---------------------------------------------------------------------------------------

#Comparaison d'une image HR et LR
st.subheader("Presentation of the data")
st.text("""The original dataset consists of grids of values representing low-resolution (LR) and high-resolution (HR) simulations. Unlike the approach taken by Bakong et al., where LR data was manually derived from HR data, our LR data was generated through an analogous simulation process that mirrors the HR simulation, but at a different resolution. This method is expected to generate more realistic data, making the resulting models better suited for real-life applications.""")
with st.container():
    video_file_LR = open('videoLowResolutionSimulation7.mp4', 'rb')
    video_bytes_LR = video_file_LR.read()
    video_file_HR = open('videoHRSimulation7.mp4', 'rb')
    video_bytes_HR = video_file_HR.read()
    # Créer deux colonnes pour aligner les vidéos côte à côte
    col1, col2 = st.columns([1, 1])  # Ajuster les proportions si nécessaire
    
    with col1:
        st.markdown("<h3 style='text-align: center;'>Vidéo LR</h3>", unsafe_allow_html=True)
        st.video(video_bytes_LR)
        video_file_LR.close()
    
    with col2:
        st.markdown("<h3 style='text-align: center;'>Vidéo HR</h3>", unsafe_allow_html=True)
        st.video(video_bytes_HR)
        video_file_HR.close()



st.text("""The input grids have dimensions of 1 × 50, which are extremely small, particularly on the vertical
axis. This presents a significant challenge for convolutional operations, as such small grids are not
well-suited for effective convolution. Furthermore, there is no vertical information in the input data,
meaning it must be entirely generated by the model.
""")

with st.container():
    image = Image.open('images/inputNOBI.png')
    image2 = Image.open('images/HRreport.png')
    col1, col2 = st.columns([1, 1])
    with col1 :
        st.image(image, caption='LR input', use_container_width=True)
    with col2 :
        st.image(image2, caption='HR label', use_container_width=True)

st.subheader("Zoom on complex areas")
st.text("""The dataset is relatively simple, with perfectly straight streets and water flowing smoothly without
turbulence. However, in the HR simulation some anomalies appear at the top of
the street, potentially indicating more complex water behavior. These anomalies are entirely absent
in the input data, making their accurate reconstruction a key challenge for the model.""")

with st.container():
    image = Image.open('images/input_zoome.png')
    image2 = Image.open('images/ground_truth_zoome.png')
    col1, col2 = st.columns([1, 1])
    with col1 :
        st.image(image2, caption='Zoom on a difficult area in HR input', use_container_width=True)
    with col2 :
        st.image(image, caption='Zoom on a difficult area in LR input', use_container_width=True)
        
st.subheader("Model Architecture")
st.text("We utilize a ConvLSTM with SR architecture")
imagemodele = Image.open('images/modelarch.png')
st.image(imagemodele, caption='Model Architecture', use_container_width=True)


st.subheader("Results")


html_code = """
<style>
    table {
        width: 100%;
        border-collapse: collapse;
        margin: auto;
    }
    th, td {
        border: 1px solid black;
        padding: 10px;
        text-align: center;
    }
    th {
        background-color: #f2f2f2;
    }
    tr:nth-child(even) {
        background-color: #f9f9f9;
    }
</style>
<table>
    <thead>
        <tr>
            <th>Interpolated</th>
            <th>Residual Connection</th>
            <th>Cost Function</th>
            <th>MSE loss</th>
            <th>RMSE + DSSIM + RSDSSIM</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>No</td>
            <td>No</td>
            <td>RMSE + DSSIM + RSSSIM</td>
            <td>9 &middot; 10<sup>-2</sup></td>
            <td>0.3</td>
        </tr>
        <tr>
            <td>Yes</td>
            <td>No</td>
            <td>RMSE + DSSIM</td>
            <td>7 &middot; 10<sup>-2</sup></td>
            <td>0.1</td>
        </tr>
        <tr>
            <td>Yes</td>
            <td>No</td>
            <td>RMSE + DSSIM + RSDSSIM</td>
            <td>7 &middot; 10<sup>-2</sup></td>
            <td>0.1</td>
        </tr>
        <tr>
            <td>Yes</td>
            <td>Yes</td>
            <td>RMSE + DSSIM + RSDSSIM</td>
            <td>4 &middot; 10<sup>-4</sup></td>
            <td>0.09</td>
        </tr>
    </tbody>
</table>
"""

# Afficher le tableau dans Streamlit
st.markdown(html_code, unsafe_allow_html=True)

st.text("""The model with residual connections is clearly the best. Adding skip connections is very common in machine learning, as they allow better gradient flow by acting as a gradient dispatcher. This is because the gradient of a sum with respect to its terms is one everywhere, so the descending gradient will flow freely through every branch of the addition. However, here it is a bit different since the skip connection bypasses the entire model and goes straight to the input. This allows the model to focus only on learning the complex patterns not found in the LR images, and not worry about the rest of the generation. \n""")


with st.container():
    image = Image.open('images/refinementonly.png')
    image2 = Image.open('images/HR_residual_plus.png')
    image3 = Image.open('images/groundtruthtwotets.png')
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1 :
        st.image(image, caption='Refinement only', use_container_width=True)
    with col2 :
        st.image(image2, caption='Input +  Refinement', use_container_width=True)
    with col3 :
        st.image(image3, caption='Ground truth', use_container_width=True)